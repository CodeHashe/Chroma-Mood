<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Chroma-Mood</title>

    <!-- Bootstrap 5 CSS from CDN -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">

    <style>
        body {
            background-color: #f8f9fa;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        .results-container {
            transition: all 0.5s ease;
        }

        .result-color-box {
            width: 300px;
            height: 300px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 0 auto;
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.1);
            animation: pulse 2s infinite;
        }

        .emotion-text {
            color: white;
            font-size: 2.5rem;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.3);
            font-weight: bold;
            text-transform: uppercase;
        }

        @keyframes pulse {
            0% {
                transform: scale(1);
            }

            50% {
                transform: scale(1.05);
            }

            100% {
                transform: scale(1);
            }
        }
    </style>
</head>

<body>
    <!-- Simple and clean navbar -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <div class="container">
            <a class="navbar-brand" href="#">Chroma-Mood</a>
        </div>
    </nav>

    <!-- Main content -->
    <main class="container mt-5">
        <div class="text-center mb-5">
            <h1 class="display-4">Chroma-Mood</h1>
            <p class="lead">Detect emotions from Text, Video, or Voice.</p>
        </div>

        <ul class="nav nav-tabs justify-content-center mb-4" id="emotionTabs" role="tablist">
            <li class="nav-item" role="presentation">
                <button class="nav-link active" id="text-tab" data-bs-toggle="tab" data-bs-target="#text" type="button"
                    role="tab">Text</button>
            </li>
            <li class="nav-item" role="presentation">
                <button class="nav-link" id="video-tab" data-bs-toggle="tab" data-bs-target="#video" type="button"
                    role="tab">Video</button>
            </li>
            <li class="nav-item" role="presentation">
                <button class="nav-link" id="voice-tab" data-bs-toggle="tab" data-bs-target="#voice" type="button"
                    role="tab">Voice</button>
            </li>
        </ul>

        <div class="tab-content" id="emotionTabsContent">
            <!-- Text Section -->
            <div class="tab-pane fade show active" id="text" role="tabpanel">
                <div class="mx-auto" style="max-width: 600px;">
                    <div class="mb-3">
                        <textarea id="user_text" class="form-control" rows="4"
                            placeholder="How are you feeling today?"></textarea>
                    </div>
                    <div class="text-center">
                        <button id="analyze-text-btn" class="btn btn-primary btn-lg">Analyze Text</button>
                    </div>
                </div>
                <div id="text-result" class="mt-4 text-center"></div>
            </div>

            <!-- Video Section -->
            <div class="tab-pane fade text-center" id="video" role="tabpanel">
                <p>Look at the camera for 10 seconds.</p>
                <div id="video-container" class="mb-3">
                    <!-- Video feed will appear here -->
                    <img id="video-feed" src="" style="max-width: 100%; display: none; border-radius: 8px;">
                </div>
                <button id="start-video-btn" class="btn btn-success btn-lg">Start Video Analysis</button>
                <div id="video-result" class="mt-4"></div>
            </div>

            <!-- Voice Section -->
            <div class="tab-pane fade text-center" id="voice" role="tabpanel">
                <p>Click to record 5 seconds of audio.</p>
                <button id="record-btn" class="btn btn-danger btn-lg">Record & Analyze</button>
                <div id="voice-status" class="mt-3 text-muted"></div>
                <div id="voice-result" class="mt-4"></div>
            </div>
        </div>
    </main>

    <!-- Bootstrap 5 JS and Popper.js from CDN -->
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.6/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.min.js"></script>

    <script>
        // --- CONFIGURATION ---
        // UPDATE THIS URL AFTER DEPLOYING TO EC2
        const API_BASE_URL = "https://44.220.175.153:5000";
        // ---------------------

        // --- Text Logic ---
        const textBtn = document.getElementById('analyze-text-btn');
        const textInput = document.getElementById('user_text');
        const textResult = document.getElementById('text-result');

        textBtn.addEventListener('click', () => {
            const text = textInput.value;
            if (!text) return;

            textBtn.disabled = true;
            textResult.innerHTML = 'Analyzing...';

            fetch(`${API_BASE_URL}/text_predict`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text: text })
            })
                .then(response => response.json())
                .then(data => {
                    textBtn.disabled = false;
                    if (data.error) {
                        textResult.innerHTML = `<div class="alert alert-warning">${data.error}</div>`;
                    } else {
                        textResult.innerHTML = `
                        <div class="p-4 rounded" style="background-color: ${data.color}; display: inline-block;">
                            <h2 class="text-white">${data.emotion}</h2>
                            <p class="text-white lead">Color: ${data.color}</p>
                        </div>
                    `;
                    }
                })
                .catch(err => {
                    textBtn.disabled = false;
                    textResult.innerHTML = `<div class="alert alert-danger">Error: ${err}</div>`;
                });
        });

        // --- Video Logic ---
        const videoBtn = document.getElementById('start-video-btn');
        const videoContainer = document.getElementById('video-container');
        const videoResult = document.getElementById('video-result');

        let videoStream = null;
        let videoInterval = null;
        const VIDEO_EMOTION_LABELS = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', "Surprise"];

        videoBtn.addEventListener('click', async () => {
            videoResult.innerHTML = '';
            videoBtn.disabled = true;

            // Create video element for preview
            videoContainer.innerHTML = '<video id="webcam-preview" autoplay playsinline style="max-width: 100%; border-radius: 8px;"></video>';
            const videoEl = document.getElementById('webcam-preview');

            try {
                videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
                videoEl.srcObject = videoStream;
            } catch (err) {
                videoResult.innerHTML = `<div class="alert alert-danger">Error accessing webcam: ${err.message}</div>`;
                videoBtn.disabled = false;
                return;
            }

            // Client-side aggregation
            let emotionScores = new Array(VIDEO_EMOTION_LABELS.length).fill(0);
            let frameCount = 0;
            const startTime = Date.now();

            // Capture frame every 500ms
            videoInterval = setInterval(async () => {
                if (Date.now() - startTime >= 10000) {
                    stopVideoAnalysis(emotionScores);
                    return;
                }

                const canvas = document.createElement('canvas');
                canvas.width = videoEl.videoWidth;
                canvas.height = videoEl.videoHeight;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(videoEl, 0, 0);

                canvas.toBlob(blob => {
                    const formData = new FormData();
                    formData.append('frame', blob, 'frame.jpg');

                    fetch(`${API_BASE_URL}/video_frame_predict`, {
                        method: 'POST',
                        body: formData
                    })
                        .then(res => res.json())
                        .then(data => {
                            if (data.status === 'success') {
                                // Aggregate scores
                                for (let i = 0; i < emotionScores.length; i++) {
                                    emotionScores[i] += data.scores[i];
                                }
                                frameCount++;
                                videoResult.innerHTML = `<p class="text-muted">Analyzing... (Frames processed: ${frameCount})</p>`;
                            }
                        })
                        .catch(console.error);
                }, 'image/jpeg');

            }, 500);
        });

        function stopVideoAnalysis(scores) {
            clearInterval(videoInterval);
            if (videoStream) {
                videoStream.getTracks().forEach(track => track.stop());
            }
            videoContainer.innerHTML = ''; // Clear video preview
            videoBtn.disabled = false;

            if (scores.reduce((a, b) => a + b, 0) === 0) {
                videoResult.innerHTML = `<div class="alert alert-warning">No faces detected or analysis failed.</div>`;
                return;
            }

            // Determine dominant emotion
            const maxScoreIndex = scores.indexOf(Math.max(...scores));
            let dominantEmotion = VIDEO_EMOTION_LABELS[maxScoreIndex];

            // Adjustments (matching backend logic)
            if (dominantEmotion === 'Surprise') dominantEmotion = 'Happy';
            if (dominantEmotion === 'Disgust') dominantEmotion = 'Angry';

            // Get color
            const colorMap = {
                'Anger': '#FF4500', 'Angry': '#FF4500',
                'Disgust': '#556B2F',
                'Fear': '#800080',
                'Happy': '#FFD700',
                'Sadness': '#1E90FF',
                'Surprise': '#00CED1',
                'Neutral': '#808080'
            };
            const color = colorMap[dominantEmotion] || '#808080';

            videoResult.innerHTML = `
                <div class="p-4 rounded" style="background-color: ${color}; display: inline-block;">
                    <h3 class="text-white">Detected: ${dominantEmotion}</h3>
                    <p class="text-white lead">Color: ${color}</p>
                </div>
            `;
        }

        // --- Voice Logic ---
        const recordBtn = document.getElementById('record-btn');
        const voiceStatus = document.getElementById('voice-status');
        const voiceResult = document.getElementById('voice-result');
        let mediaRecorder;
        let audioChunks = [];

        recordBtn.addEventListener('click', async () => {
            voiceResult.innerHTML = '';
            voiceStatus.innerText = "Requesting microphone access...";
            recordBtn.disabled = true;

            try {
                // Check supported MIME types
                const mimeType = MediaRecorder.isTypeSupported('audio/webm') ? 'audio/webm' : 'audio/mp4';
                console.log("Using MIME type:", mimeType);

                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream, { mimeType: mimeType });
                audioChunks = [];

                mediaRecorder.ondataavailable = event => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: mimeType });
                    console.log("Audio Blob Size:", audioBlob.size);
                    console.log("Audio Blob Type:", audioBlob.type);

                    if (audioBlob.size === 0) {
                        voiceResult.innerHTML = `<div class="alert alert-warning">Recorded audio is empty.</div>`;
                        recordBtn.disabled = false;
                        return;
                    }

                    const formData = new FormData();
                    // Filename extension depends on mimeType
                    const ext = mimeType.split('/')[1];
                    formData.append('file', audioBlob, `recording.${ext}`);

                    voiceStatus.innerText = "Analyzing audio...";

                    fetch(`${API_BASE_URL}/voice_predict`, {
                        method: 'POST',
                        body: formData
                    })
                        .then(res => res.json())
                        .then(data => {
                            voiceStatus.innerText = "";
                            recordBtn.disabled = false;
                            if (data.error) {
                                voiceResult.innerHTML = `<div class="alert alert-warning">${data.error}</div>`;
                            } else {
                                voiceResult.innerHTML = `
                                <div class="p-4 rounded" style="background-color: ${data.color}; display: inline-block;">
                                    <h3 class="text-white">Detected: ${data.emotion.toUpperCase()} (Confidence: ${data.confidence.toFixed(2)})</h3>
                                    <p class="text-white lead">Color: ${data.color}</p>
                                </div>
                            `;
                            }
                        })
                        .catch(err => {
                            voiceStatus.innerText = "";
                            recordBtn.disabled = false;
                            voiceResult.innerHTML = `<div class="alert alert-danger">Error: ${err.message}</div>`;
                        });
                };

                mediaRecorder.start();
                voiceStatus.innerText = "Recording... (Speak now)";

                setTimeout(() => {
                    mediaRecorder.stop();
                    stream.getTracks().forEach(track => track.stop());
                }, 5000);

            } catch (err) {
                voiceStatus.innerText = "";
                recordBtn.disabled = false;
                voiceResult.innerHTML = `<div class="alert alert-danger">Microphone access denied or error: ${err.message}</div>`;
            }
        });
    </script>
</body>

</html>